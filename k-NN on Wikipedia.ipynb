{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "COMP 614\n",
        "Homework 5: Bag of Words\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "_Xo_0bp3U2a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "AJ5geeelU4J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title_and_text(filename):\n",
        "    \"\"\"\n",
        "    Given a the name of an XML file, extracts and returns the strings contained \n",
        "    between the <title></title> and <text></text> tags.\n",
        "    \"\"\"\n",
        "    from bs4 import BeautifulSoup\n",
        "\n",
        "    root = \"/content/drive/MyDrive/hw5/\"  #change the root as per your system\n",
        "    filepath = root + filename\n",
        "\n",
        "    file_contents = open(filepath, encoding=\"utf-8\").read()\n",
        "    soup = BeautifulSoup(file_contents)\n",
        "\n",
        "    title = soup.find('title')\n",
        "    title = title.text\n",
        "\n",
        "    text = soup.find('text')\n",
        "    text = text.text\n",
        "    return title, text\n"
      ],
      "metadata": {
        "id": "ucwp9qe5U7sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words(text):\n",
        "    \"\"\"\n",
        "    Given the full text of an XML file, filters out the non-body text (text that\n",
        "    is contained within {{}}, [[]], [], <>, etc.) and punctuation and returns a \n",
        "    list of the remaining words, each of which should be converted to lowercase.\n",
        "    \"\"\"\n",
        "    remove_punc = re.sub(r'[^\\w\\s]', '', text)\n",
        "    patn = re.sub(r\"[\\([{})\\]]\", \"\", remove_punc)\n",
        "    all_lower = text.lower()\n",
        "    word_list = all_lower.split()\n",
        "    return word_list\n"
      ],
      "metadata": {
        "id": "hqZsWQm1VBRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(words):\n",
        "    \"\"\"\n",
        "    Given a list of words, returns the total number of words as well as a \n",
        "    dictionary mapping each unique word to its frequency of occurrence.\n",
        "    \"\"\"\n",
        "    unq_words = set(words)          # getting unique words\n",
        "    word_to_dict = {word: words.count(word) for word in unq_words}      #counting frequency of each unique word in a dict\n",
        "    return 0, word_to_dict\n"
      ],
      "metadata": {
        "id": "IvojkQYAVEdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_all_words(filenames):\n",
        "    \"\"\"\n",
        "    Given a list of filenames, returns three things. First, a list of the titles,\n",
        "    where the i-th title corresponds to the i-th input filename. Second, a\n",
        "    dictionary mapping each filename to an inner dictionary mapping each unique\n",
        "    word in that file to its relative frequency of occurrence. Last, a dictionary \n",
        "    mapping each unique word --- including all words found across all files --- \n",
        "    to its total frequency of occurrence across all of the input files.\n",
        "    \"\"\"\n",
        "    all_titles = []\n",
        "    unk_word_each_file = {}\n",
        "    title_to_counter = {}\n",
        "\n",
        "    for filename in filenames:\n",
        "        title, text = get_title_and_text(filename)\n",
        "        all_titles.append(title)    # creating title list\n",
        "        all_words_in_file = get_words(text)\n",
        "        _, unk_word_in_file = count_words(all_words_in_file)\n",
        "        unk_word_each_file[filename] = unk_word_in_file         #dictionary => filename: count_word_dict\n",
        "        total_words = sum(unk_word_in_file.values())\n",
        "        count_normalize = {}\n",
        "        for word in unk_word_in_file:\n",
        "            count_normalize[word] = float(unk_word_in_file[word] / total_words)\n",
        "        title_to_counter[filename] = count_normalize            # dictionary => filename: word_counts_normalized\n",
        "\n",
        "\n",
        "\n",
        "    unk_word_all_file = list(set(word for filename in unk_word_each_file for word in unk_word_each_file[filename]))  # unique words in all files \n",
        "    total_counts = {}\n",
        "    temp = []\n",
        "    for word in unk_word_all_file:\n",
        "        for filename in unk_word_each_file:\n",
        "            temp.append(unk_word_each_file[filename].get(word))\n",
        "            word_count = [count for count in temp if count]\n",
        "            total_counts[word] = sum(word_count)           #dictionary => unique words : unique_words_count\n",
        "        temp.clear()\n",
        "    \n",
        "    \n",
        "\n",
        "    return all_titles, title_to_counter, total_counts"
      ],
      "metadata": {
        "id": "2tx08RHZVJdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_word_counts(all_titles, title_to_counter, total_counts, num_words):\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Given two dictionaries in the format output by count_all_words and an integer\n",
        "    num_words representing the number of top words to encode, finds the top \n",
        "    num_words words in total_counts and builds a matrix where the element in \n",
        "    position (i, j) is the relative frequency of occurrence of the j-th most \n",
        "    common overall word in the i-th article (i.e., the article corresponding to \n",
        "    the i-th title in titles).\n",
        "    \"\"\"\n",
        "    sorted_words = sorted(total_counts.items(), key=lambda tup: (-1*tup[1], tup[0]))\n",
        "    top_k_words = sorted_words[:num_words]\n",
        "\n",
        "    top_k_counter = [[] for i in range((len(top_k_words)))]\n",
        "\n",
        "    top_words = numpy.zeros((len(title_to_counter), len(top_k_words)))\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for filename in title_to_counter:\n",
        "        for top_word in range(len(top_k_words)):\n",
        "            top_k_counter[top_word] = title_to_counter[filename].get(top_k_words[top_word][0])\n",
        "\n",
        "            if top_k_counter[top_word] is None:\n",
        "                top_k_counter[top_word] = 0\n",
        "\n",
        "        top_words[counter] = top_k_counter\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    return numpy.matrix(top_words)\n"
      ],
      "metadata": {
        "id": "d7zei4WJVOTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbors(matrix, all_titles, title, num_nbrs):\n",
        "    \"\"\"\n",
        "    Given a matrix, a list of all titles whose data is encoded in the matrix, such\n",
        "    that the i-th title corresponds to the i-th row, a single title whose data is\n",
        "    encoded in the matrix, and the desired number of neighbors to be found, finds \n",
        "    and returns the closest neighbors to the article with the given title.\n",
        "    \"\"\"\n",
        "    title_num = all_titles.index(title)\n",
        "    distance_mat = []\n",
        "    for i in range(matrix.shape[0]):\n",
        "        distance = numpy.sqrt(numpy.sum(numpy.square(matrix[title_num] - matrix[i])))\n",
        "        distance_mat.append(distance)\n",
        "\n",
        "    nearest_nbr = numpy.argsort(distance_mat)\n",
        "\n",
        "    nearest_nbr_titles = [all_titles[title] for title in nearest_nbr]\n",
        "\n",
        "    k_nearest_nbr_titles = nearest_nbr_titles[1: (num_nbrs+1)]\n",
        "\n",
        "\n",
        "    return k_nearest_nbr_titles"
      ],
      "metadata": {
        "id": "Q07gRz5GVReq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you're using colab, uncomment the below lines:\n",
        "'''\n",
        "import sys\n",
        "root = \"/content/drive/MyDrive/hw5/\"\n",
        "sys.path.append(root)\n",
        "import comp614_module5\n",
        "'''"
      ],
      "metadata": {
        "id": "SzRU_3-2f0-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    \"\"\"\n",
        "    Encodes the wikipedia dataset into a matrix, prompts the user to choose an\n",
        "    article, and then runs the knn algorithm to find the 5 nearest neighbors\n",
        "    of the chosen article.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encode the wikipedia dataset in a matrix\n",
        "    \n",
        "\n",
        "    filenames = comp614_module5.ALL_FILES   # change the comp614_module as per your filepath\n",
        "    all_titles, title_to_counter, total_counts = count_all_words(filenames)\n",
        "    mat = encode_word_counts(all_titles, title_to_counter, total_counts, 20000)\n",
        "\n",
        "    # Print all articles\n",
        "    print(\"Enter the integer corresponding to the article whose nearest\" +\n",
        "          \" neighbors you would like to find. Your options are:\")\n",
        "    for idx in range(len(all_titles)):\n",
        "        print(\"\\t\" + str(idx) + \". \" + all_titles[idx])\n",
        "\n",
        "    # Prompt the user to choose an article\n",
        "    while True:\n",
        "        choice = input(\"Enter your choice here: \")\n",
        "        try:\n",
        "            choice = int(choice)\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Error: you must enter an integer between 0 and \" +\n",
        "                  str(len(all_titles) - 1) + \", inclusive.\")\n",
        "\n",
        "    # Compute and print the results\n",
        "    nbrs = nearest_neighbors(mat, all_titles, all_titles[choice], 5)\n",
        "    print(\"\\nThe 5 nearest neighbors of \" + all_titles[choice] + \" are:\")\n",
        "    for nbr in nbrs:\n",
        "        print(\"\\t\" + nbr)"
      ],
      "metadata": {
        "id": "qpj6xDbVVOwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Function to answer discussion question\n",
        "\n",
        "def top_words_in_article(id):\n",
        "    filenames = comp614_module5.ALL_FILES\n",
        "    filename = filenames[id]\n",
        "    file_title, file_text = get_title_and_text(filename)\n",
        "    file_words = get_words(file_text)\n",
        "    _, file_word_count = count_words(file_words)\n",
        "    file_word_count_sorted = sorted(file_word_count.items(), key=lambda x:x[1], reverse = True)\n",
        "    top_30_words = [file_word_count_sorted[:30]]\n",
        "\n",
        "    return top_30_words"
      ],
      "metadata": {
        "id": "htCj_ro8vACn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IrdyW9F4ShtQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}